__version__ = (2, 0, 1)

#             ‚ñà ‚ñà ‚ñÄ ‚ñà‚ñÑ‚ñÄ ‚ñÑ‚ñÄ‚ñà ‚ñà‚ñÄ‚ñà ‚ñÄ
#             ‚ñà‚ñÄ‚ñà ‚ñà ‚ñà ‚ñà ‚ñà‚ñÄ‚ñà ‚ñà‚ñÄ‚ñÑ ‚ñà
#              ¬© Copyright 2022
#           https://t.me/hikariatama
#
# üîí      Licensed under the GNU AGPLv3
# üåê https://www.gnu.org/licenses/agpl-3.0.html

# meta pic: https://static.hikari.gay/vtt_icon.png
# meta banner: https://mods.hikariatama.ru/badges/vtt.jpg
# meta developer: @hikarimods
# scope: ffmpeg
# scope: hikka_only
# scope: hikka_min 1.3.3
# requires: pydub speechrecognition python-ffmpeg

import asyncio
import tempfile
import os
import logging

import speech_recognition as sr
from pydub import AudioSegment
from telethon.tl.types import Message, DocumentAttributeVideo

from .. import loader, utils

logger = logging.getLogger(__name__)


@loader.tds
class VoicyMod(loader.Module):
    """Recognize voice messages, audios, videos and round messages"""

    strings = {
        "name": "Voicy",
        "converting": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> Recognizing voice"
            " message...</b>"
        ),
        "converted": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji>"
            " Recognized:</b>\n<i>{}</i>"
        ),
        "voice_not_found": (
            "<emoji document_id='6041850934756119589'>ü´†</emoji> <b>Voice not found</b>"
        ),
        "autovoice_off": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> I will not recognize"
            " voice messages in this chat</b>"
        ),
        "autovoice_on": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> I will recognize"
            " voice messages in this chat</b>"
        ),
        "_cfg_lang": "Language of voices to recognize",
        "_cfg_engine": "Recognition engine",
        "error": "üö´ <b>Recognition error!</b>",
        "_cfg_ignore_users": "Users to ignore",
        "_cfg_silent": "Silent mode - do not notify about errors",
        "too_big": "ü´• <b>Voice message is too big, I can't recognise it...</b>",
    }

    strings_ru = {
        "converting": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ"
            " —Å–æ–æ–±—â–µ–Ω–∏–µ...</b>"
        ),
        "converted": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji>"
            " –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ:</b>\n<i>{}</i>"
        ),
        "voice_not_found": (
            "<emoji document_id='6041850934756119589'>ü´†</emoji> <b>–ù–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞"
            " –≤–æ–π—Å</b>"
        ),
        "autovoice_off": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> –Ø –±–æ–ª—å—à–µ –Ω–µ –±—É–¥—É"
            " —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–æ–º —á–∞—Ç–µ</b>"
        ),
        "autovoice_on": (
            "<b><emoji document_id='6041850934756119589'>ü´†</emoji> –Ø –±—É–¥—É —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç—å"
            " –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ —ç—Ç–æ–º —á–∞—Ç–µ</b>"
        ),
        "_cmd_doc_voicy": "–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ",
        "_cmd_doc_autovoice": (
            "–í–∫–ª—é—á–∏—Ç—å\\–≤—ã–∫–ª—é—á–∏—Ç—å –∞–≤—Ç–æ—Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ —á–∞—Ç–µ"
        ),
        "_cls_doc": "–†–∞—Å–ø–æ–∑–Ω–∞–µ—Ç –≥–æ–ª–æ—Å–æ–≤—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è, –∞—É–¥–∏–æ, –≤–∏–¥–µ–æ –∏ –∫—Ä—É–≥–ª—è—à–∏",
        "_cfg_lang": "–Ø–∑—ã–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –≥–æ–ª–æ—Å–æ–≤—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π",
        "_cfg_engine": "–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å",
        "_cfg_ignore_users": "–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π",
        "_cfg_silent": "–¢–∏—Ö–∏–π —Ä–µ–∂–∏–º - –Ω–µ –æ–ø–æ–≤–µ—â–∞—Ç—å –æ–± –æ—à–∏–±–∫–∞—Ö",
        "error": "üö´ <b>–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è!</b>",
        "too_big": (
            "ü´• <b>–ì–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –±–æ–ª—å—à–æ–µ, —è –Ω–µ –º–æ–≥—É –µ–≥–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å...</b>"
        ),
    }

    def __init__(self):
        self.config = loader.ModuleConfig(
            loader.ConfigValue(
                "language",
                "ru-RU",
                lambda: self.strings("_cfg_lang"),
                validator=loader.validators.RegExp(r"^[a-z]{2}-[A-Z]{2}$"),
            ),
            loader.ConfigValue(
                "ignore_users",
                [],
                lambda: self.strings("_cfg_ignore_users"),
                validator=loader.validators.Series(
                    validator=loader.validators.TelegramID()
                ),
            ),
            loader.ConfigValue(
                "silent",
                False,
                lambda: self.strings("_cfg_silent"),
                validator=loader.validators.Boolean(),
            ),
        )

    async def client_ready(self):
        self.v2a = await self.import_lib(
            "https://libs.hikariatama.ru/v2a.py",
            suspend_on_error=True,
        )
        self.chats = self.pointer("chats", [])

    async def recognize(self, message: Message):
        try:
            m = await utils.answer(message, self.strings("converting"))
            with tempfile.TemporaryDirectory() as tmpdir:
                file = os.path.join(
                    tmpdir,
                    "audio.mp3" if message.audio else "audio.ogg",
                )

                data = await message.download_media(bytes)

                if message.video:
                    data = await self.v2a.convert(data, "audio.ogg")

                with open(file, "wb") as f:
                    f.write(data)

                song = AudioSegment.from_file(
                    file, format="mp3" if message.audio else "ogg"
                )
                song.export(os.path.join(tmpdir, "audio.wav"), format="wav")

                r = sr.Recognizer()

                with sr.AudioFile(os.path.join(tmpdir, "audio.wav")) as source:
                    audio_data = r.record(source)
                    text = await utils.run_sync(
                        r.recognize_google,
                        audio_data,
                        language=self.config["language"],
                    )
                    m = await utils.answer(
                        m,
                        self.strings("converted").format(text),
                    )
        except Exception:
            logger.exception("Can't recognize")
            if not self.config["silent"]:
                m = await utils.answer(m, self.strings("error"))
                await asyncio.sleep(3)
                if not message.out:
                    await m.delete()

    @loader.unrestricted
    async def voicycmd(self, message: Message):
        """Recognize voice message"""
        reply = await message.get_reply_message()
        try:
            is_voice = (
                reply.video or reply.audio or reply.media.document.attributes[0].voice
            )
        except (AttributeError, IndexError):
            is_voice = False

        if not reply or not reply.media or not is_voice:
            await utils.answer(message, self.strings("voice_not_found"))
            return

        if message.out:
            await message.delete()

        await self.recognize(reply)

        if message.out:
            await message.delete()

    async def watcher(self, message: Message):
        try:
            if (
                utils.get_chat_id(message) not in self.get("chats", [])
                or not message.media
                or not message.video
                and not message.audio
                and not message.media.document.attributes[0].voice
                or message.gif
                or message.sticker
            ):
                return
        except Exception:
            return

        if message.sender_id in self.config["ignore_users"]:
            return

        if (
            (
                message.video
                and (
                    next(
                        attr
                        for attr in message.video.attributes
                        if isinstance(attr, DocumentAttributeVideo)
                    ).duration
                    > 120
                )
            )
            or getattr(
                (
                    getattr(
                        getattr(getattr(message, "media", None), "document", None),
                        "attributes",
                        False,
                    )
                    or [None]
                )[0],
                "duration",
                0,
            )
            > 300
            or message.document.size / 1024 / 1024 > 5
        ):
            if not self.config["silent"]:
                await utils.answer(message, self.strings("too_big"))
            return

        await self.recognize(message)

    async def autovoicecmd(self, message: Message):
        """Toggle automatic recognition in current chat"""
        chat_id = utils.get_chat_id(message)

        if chat_id in self.get("chats", []):
            self.chats.remove(chat_id)
            await utils.answer(message, self.strings("autovoice_off"))
        else:
            self.chats.append(chat_id)
            await utils.answer(message, self.strings("autovoice_on"))
